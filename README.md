## Cognitive neuroscientist üëÅ‚úãüß†

### Current appointments
[Research Scientist, Wolpert Lab](https://wolpertlab.neuroscience.columbia.edu)

### About my work
The goal of my research is to understand how humans learn to **skillfully interact with physical objects**. Object manipulation is an essential ability in daily life and can be devastatingly disrupted by illness or injury, making it an impactful topic in its own right. Viewed more broadly, it's also an excellent model behavior for cognitive neuroscience because it naturally recruits many different types of neural processing and has high ecological validity. Just scratching the surface, it's easy to see the involvement of neural systems for <a href="javascript:void(0)" data-toggle="tooltip" title="" data-html="true" data-original-title="&bull; 3D shape analysis<br>&bull; object recognition<br>&bull; haptic feedback<br>&bull; multisensory integration"><b>perception</b></a>, <a href="javascript:void(0)" data-toggle="tooltip" title="" data-html="true" data-original-title="&bull; generalization<br>&bull; prediction errors<br>&bull; cost functions<br>&bull; representational formats"><b>learning and memory</b></a>, <a href="javascript:void(0)" data-toggle="tooltip" title="" data-html="true" data-original-title="&bull; sequential planning<br>&bull; intuitive physics<br>&bull; tool use & design"><b>reasoning</b></a>, as well as <a href="javascript:void(0)" data-toggle="tooltip" title="" data-html="true" data-original-title="&bull; action understanding<br>&bull; gesture & pantomime"><b>social cognition and communication</b></a>. One of the big ideas motivating my research is that human intelligence has been significantly shaped by the computational problem of adaptively controlling interactions with many different objects.

I have a lot of fun working with all kinds of **interactive technology**. When I'm not thinking about brains and behavior, I'm keeping up with the latest trends in **3D graphics, haptic interfaces, interactive design, web-based research, UX, VR/AR, and more**. In the classroom, I've seen how incorporating these technologies in demos and projects draws out a desire to learn and practice science in students from all backgrounds. I believe this style of hands-on, active learning leads to flexible and expressive knowledge that enables students to make meaningful individual contributions.

In my experiments, I blend these interactive methods to create both real and virtual modes of object interaction. I've successfully applied this approach to address a range of research questions in psychology and neuroscience. In some of my work, I've examined the **mechanisms of behavioral and psychophysical phenomena** in sensorimotor tasks, such as how we shape our hands to interact with 3D objects, or how 3D motion perception is affected by internally generated predictions. In other work, I've engaged in thorny **debates in the philosophy of mind**, particularly regarding the relationship between real-time action and conscious visual perception. Most recently, I've been developing a new perspective on the **computational principles of sensorimotor-repertoire learning** by demonstrating how set of objects with different visual and mechanical properties are encoded in memory.

I also maintain the open-source <b><a href="https://www.github.com/EvanCesanek/weblab" target="_blank">weblab</a></b> project, which aims to help researchers develop and run crowdsourced behavioral experiments using MTurk and Prolific. <b>weblab</b> consists of a command-line interface for managing experiments, plus a core experiment library that streamlines the process of developing complex interactive experiments in performant modern JavaScript.
